
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>üìå Binning (Diskritisasi) Menggunakan K-Means Clustering &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Binning (Diskritisasi Menggunakan K-Mean Clustering)';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Analisis dan Implementasi Model Machine Learning untuk Klasifikasi Jamur (Beracun vs. Dapat Dimakan) pada Secondary Mushroom Dataset" href="Pra_Uas.html" />
    <link rel="prev" title="üå≥ Apa Itu Decision Tree?" href="Decision%20Tree.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to my website
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Penambangan%20Data%20_Data%20Understanding.html"><strong>Data Understanding</strong></a></li>







<li class="toctree-l1"><a class="reference internal" href="Mencari%20Outlayer.html"><strong>Mendeteksi Outlier Menggunakan K-Nearest Neighbors (KNN)</strong></a></li>






<li class="toctree-l1"><a class="reference internal" href="Local%20Outlier%20Factor%20%28LOF%29.html"><strong>Local Outlier Factor</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="Naive%20Bayes.html"><strong>Naive Bayes</strong></a></li>




<li class="toctree-l1"><a class="reference internal" href="23-112_Fariel%20Nur%20Rizky%20Maulana_UTS_Pendat.html"><strong>Upload File csv</strong></a></li>


<li class="toctree-l1"><a class="reference internal" href="K-Mean.html"><strong>K-Mean</strong></a></li>














<li class="toctree-l1"><a class="reference internal" href="Decision%20Tree.html"><strong>üå≥ Apa Itu Decision Tree?</strong></a></li>


<li class="toctree-l1 current active"><a class="current reference internal" href="#"><strong>üìå Binning (Diskritisasi) Menggunakan K-Means Clustering</strong></a></li>


<li class="toctree-l1"><a class="reference internal" href="Pra_Uas.html"><strong>Analisis dan Implementasi Model Machine Learning untuk Klasifikasi Jamur (Beracun vs. Dapat Dimakan) pada Secondary Mushroom Dataset</strong></a></li>






<li class="toctree-l1"><a class="reference internal" href="UAS.html"><strong>Analisis Faktor Risiko Kanker Serviks Menggunakan Metode Klasifikasi Machine Learning</strong></a></li>

</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FBinning (Diskritisasi Menggunakan K-Mean Clustering).html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/Binning (Diskritisasi Menggunakan K-Mean Clustering).ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>üìå Binning (Diskritisasi) Menggunakan K-Means Clustering</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#"><strong>üìå Binning (Diskritisasi) Menggunakan K-Means Clustering</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#apa-itu-k-means-clustering-untuk-diskritisasi"><strong>ü§ñ Apa Itu K-Means Clustering untuk Diskritisasi?</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#import-library-yang-diperlukan">Import library yang diperlukan</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#memuat-data-iris">Memuat Data Iris</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diskritisasi-data-dengan-k-means-clustering-binning">üìä Diskritisasi Data dengan K-Means Clustering (Binning)</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pembagian-data-train-test-split-untuk-data-asli-dan-data-diskritisasi">‚úÇÔ∏è Pembagian Data (Train-Test Split) untuk Data Asli dan Data Diskritisasi</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-klasifikasi-naive-bayes-pada-data-asli-dan-data-yang-didiskritisasi">üìä Perbandingan Klasifikasi Naive Bayes pada Data Asli dan Data yang Didiskritisasi</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hasil-evaluasi-naive-bayes-data-asli-vs-data-diskritisasi">‚úÖ Hasil Evaluasi Naive Bayes: Data Asli vs Data Diskritisasi</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data-asli-numerik">üìå Data Asli (Numerik)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data-diskritisasi-hasil-k-means">üìå Data Diskritisasi (Hasil K-Means)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan">üéØ Kesimpulan</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-klasifikasi-decision-tree-pada-data-asli-dan-data-yang-didiskritisasi">üìä Perbandingan Klasifikasi Decision Tree pada Data Asli dan Data yang Didiskritisasi</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluasi-model-decision-tree-data-asli-vs-data-diskritisasi">üå≥ Evaluasi Model Decision Tree: Data Asli vs Data Diskritisasi</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">üìå Data Asli (Numerik)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data-diskritisasi-k-means">üìå Data Diskritisasi (K-Means)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">‚úÖ Kesimpulan</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-global-model-klasifikasi-naive-bayes-vs-decision-tree">üìä Perbandingan Global Model Klasifikasi: Naive Bayes vs Decision Tree</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#insight-utama">üîç Insight Utama</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="binning-diskritisasi-menggunakan-k-means-clustering">
<h1><strong>üìå Binning (Diskritisasi) Menggunakan K-Means Clustering</strong><a class="headerlink" href="#binning-diskritisasi-menggunakan-k-means-clustering" title="Link to this heading">#</a></h1>
<p>üéØ Tujuan
Diskritisasi (binning) adalah proses mengubah data numerik kontinu menjadi bentuk kategorikal (diskrit). Teknik ini sering digunakan untuk:</p>
<p>Menyederhanakan model klasifikasi</p>
<p>Mengurangi noise dalam data</p>
<p>Membantu interpretasi data</p>
<p>Salah satu pendekatan diskritisasi yang lebih fleksibel dibanding fixed-width binning adalah menggunakan K-Means Clustering.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="apa-itu-k-means-clustering-untuk-diskritisasi">
<h1><strong>ü§ñ Apa Itu K-Means Clustering untuk Diskritisasi?</strong><a class="headerlink" href="#apa-itu-k-means-clustering-untuk-diskritisasi" title="Link to this heading">#</a></h1>
<p>Alih-alih membuat interval berdasarkan rentang nilai (misalnya ‚Äúlow‚Äù, ‚Äúmedium‚Äù, ‚Äúhigh‚Äù), K-Means digunakan untuk mengelompokkan nilai-nilai numerik menjadi klaster, berdasarkan kesamaan nilai. Setiap klaster akan dianggap sebagai satu bin.</p>
<section id="import-library-yang-diperlukan">
<h2>Import library yang diperlukan<a class="headerlink" href="#import-library-yang-diperlukan" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.preprocessing</span><span class="w"> </span><span class="kn">import</span> <span class="n">KBinsDiscretizer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.naive_bayes</span><span class="w"> </span><span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.tree</span><span class="w"> </span><span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tabulate</span><span class="w"> </span><span class="kn">import</span> <span class="n">tabulate</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="memuat-data-iris">
<h2>Memuat Data Iris<a class="headerlink" href="#memuat-data-iris" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load dataset</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">load_iris</span>

<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>

<span class="c1"># display(X)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s1">&#39;keys&#39;</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s1">&#39;psql&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+-----+---------------------+--------------------+---------------------+--------------------+
|     |   sepal length (cm) |   sepal width (cm) |   petal length (cm) |   petal width (cm) |
|-----+---------------------+--------------------+---------------------+--------------------|
|   0 |                 5.1 |                3.5 |                 1.4 |                0.2 |
|   1 |                 4.9 |                3   |                 1.4 |                0.2 |
|   2 |                 4.7 |                3.2 |                 1.3 |                0.2 |
|   3 |                 4.6 |                3.1 |                 1.5 |                0.2 |
|   4 |                 5   |                3.6 |                 1.4 |                0.2 |
|   5 |                 5.4 |                3.9 |                 1.7 |                0.4 |
|   6 |                 4.6 |                3.4 |                 1.4 |                0.3 |
|   7 |                 5   |                3.4 |                 1.5 |                0.2 |
|   8 |                 4.4 |                2.9 |                 1.4 |                0.2 |
|   9 |                 4.9 |                3.1 |                 1.5 |                0.1 |
|  10 |                 5.4 |                3.7 |                 1.5 |                0.2 |
|  11 |                 4.8 |                3.4 |                 1.6 |                0.2 |
|  12 |                 4.8 |                3   |                 1.4 |                0.1 |
|  13 |                 4.3 |                3   |                 1.1 |                0.1 |
|  14 |                 5.8 |                4   |                 1.2 |                0.2 |
|  15 |                 5.7 |                4.4 |                 1.5 |                0.4 |
|  16 |                 5.4 |                3.9 |                 1.3 |                0.4 |
|  17 |                 5.1 |                3.5 |                 1.4 |                0.3 |
|  18 |                 5.7 |                3.8 |                 1.7 |                0.3 |
|  19 |                 5.1 |                3.8 |                 1.5 |                0.3 |
|  20 |                 5.4 |                3.4 |                 1.7 |                0.2 |
|  21 |                 5.1 |                3.7 |                 1.5 |                0.4 |
|  22 |                 4.6 |                3.6 |                 1   |                0.2 |
|  23 |                 5.1 |                3.3 |                 1.7 |                0.5 |
|  24 |                 4.8 |                3.4 |                 1.9 |                0.2 |
|  25 |                 5   |                3   |                 1.6 |                0.2 |
|  26 |                 5   |                3.4 |                 1.6 |                0.4 |
|  27 |                 5.2 |                3.5 |                 1.5 |                0.2 |
|  28 |                 5.2 |                3.4 |                 1.4 |                0.2 |
|  29 |                 4.7 |                3.2 |                 1.6 |                0.2 |
|  30 |                 4.8 |                3.1 |                 1.6 |                0.2 |
|  31 |                 5.4 |                3.4 |                 1.5 |                0.4 |
|  32 |                 5.2 |                4.1 |                 1.5 |                0.1 |
|  33 |                 5.5 |                4.2 |                 1.4 |                0.2 |
|  34 |                 4.9 |                3.1 |                 1.5 |                0.2 |
|  35 |                 5   |                3.2 |                 1.2 |                0.2 |
|  36 |                 5.5 |                3.5 |                 1.3 |                0.2 |
|  37 |                 4.9 |                3.6 |                 1.4 |                0.1 |
|  38 |                 4.4 |                3   |                 1.3 |                0.2 |
|  39 |                 5.1 |                3.4 |                 1.5 |                0.2 |
|  40 |                 5   |                3.5 |                 1.3 |                0.3 |
|  41 |                 4.5 |                2.3 |                 1.3 |                0.3 |
|  42 |                 4.4 |                3.2 |                 1.3 |                0.2 |
|  43 |                 5   |                3.5 |                 1.6 |                0.6 |
|  44 |                 5.1 |                3.8 |                 1.9 |                0.4 |
|  45 |                 4.8 |                3   |                 1.4 |                0.3 |
|  46 |                 5.1 |                3.8 |                 1.6 |                0.2 |
|  47 |                 4.6 |                3.2 |                 1.4 |                0.2 |
|  48 |                 5.3 |                3.7 |                 1.5 |                0.2 |
|  49 |                 5   |                3.3 |                 1.4 |                0.2 |
|  50 |                 7   |                3.2 |                 4.7 |                1.4 |
|  51 |                 6.4 |                3.2 |                 4.5 |                1.5 |
|  52 |                 6.9 |                3.1 |                 4.9 |                1.5 |
|  53 |                 5.5 |                2.3 |                 4   |                1.3 |
|  54 |                 6.5 |                2.8 |                 4.6 |                1.5 |
|  55 |                 5.7 |                2.8 |                 4.5 |                1.3 |
|  56 |                 6.3 |                3.3 |                 4.7 |                1.6 |
|  57 |                 4.9 |                2.4 |                 3.3 |                1   |
|  58 |                 6.6 |                2.9 |                 4.6 |                1.3 |
|  59 |                 5.2 |                2.7 |                 3.9 |                1.4 |
|  60 |                 5   |                2   |                 3.5 |                1   |
|  61 |                 5.9 |                3   |                 4.2 |                1.5 |
|  62 |                 6   |                2.2 |                 4   |                1   |
|  63 |                 6.1 |                2.9 |                 4.7 |                1.4 |
|  64 |                 5.6 |                2.9 |                 3.6 |                1.3 |
|  65 |                 6.7 |                3.1 |                 4.4 |                1.4 |
|  66 |                 5.6 |                3   |                 4.5 |                1.5 |
|  67 |                 5.8 |                2.7 |                 4.1 |                1   |
|  68 |                 6.2 |                2.2 |                 4.5 |                1.5 |
|  69 |                 5.6 |                2.5 |                 3.9 |                1.1 |
|  70 |                 5.9 |                3.2 |                 4.8 |                1.8 |
|  71 |                 6.1 |                2.8 |                 4   |                1.3 |
|  72 |                 6.3 |                2.5 |                 4.9 |                1.5 |
|  73 |                 6.1 |                2.8 |                 4.7 |                1.2 |
|  74 |                 6.4 |                2.9 |                 4.3 |                1.3 |
|  75 |                 6.6 |                3   |                 4.4 |                1.4 |
|  76 |                 6.8 |                2.8 |                 4.8 |                1.4 |
|  77 |                 6.7 |                3   |                 5   |                1.7 |
|  78 |                 6   |                2.9 |                 4.5 |                1.5 |
|  79 |                 5.7 |                2.6 |                 3.5 |                1   |
|  80 |                 5.5 |                2.4 |                 3.8 |                1.1 |
|  81 |                 5.5 |                2.4 |                 3.7 |                1   |
|  82 |                 5.8 |                2.7 |                 3.9 |                1.2 |
|  83 |                 6   |                2.7 |                 5.1 |                1.6 |
|  84 |                 5.4 |                3   |                 4.5 |                1.5 |
|  85 |                 6   |                3.4 |                 4.5 |                1.6 |
|  86 |                 6.7 |                3.1 |                 4.7 |                1.5 |
|  87 |                 6.3 |                2.3 |                 4.4 |                1.3 |
|  88 |                 5.6 |                3   |                 4.1 |                1.3 |
|  89 |                 5.5 |                2.5 |                 4   |                1.3 |
|  90 |                 5.5 |                2.6 |                 4.4 |                1.2 |
|  91 |                 6.1 |                3   |                 4.6 |                1.4 |
|  92 |                 5.8 |                2.6 |                 4   |                1.2 |
|  93 |                 5   |                2.3 |                 3.3 |                1   |
|  94 |                 5.6 |                2.7 |                 4.2 |                1.3 |
|  95 |                 5.7 |                3   |                 4.2 |                1.2 |
|  96 |                 5.7 |                2.9 |                 4.2 |                1.3 |
|  97 |                 6.2 |                2.9 |                 4.3 |                1.3 |
|  98 |                 5.1 |                2.5 |                 3   |                1.1 |
|  99 |                 5.7 |                2.8 |                 4.1 |                1.3 |
| 100 |                 6.3 |                3.3 |                 6   |                2.5 |
| 101 |                 5.8 |                2.7 |                 5.1 |                1.9 |
| 102 |                 7.1 |                3   |                 5.9 |                2.1 |
| 103 |                 6.3 |                2.9 |                 5.6 |                1.8 |
| 104 |                 6.5 |                3   |                 5.8 |                2.2 |
| 105 |                 7.6 |                3   |                 6.6 |                2.1 |
| 106 |                 4.9 |                2.5 |                 4.5 |                1.7 |
| 107 |                 7.3 |                2.9 |                 6.3 |                1.8 |
| 108 |                 6.7 |                2.5 |                 5.8 |                1.8 |
| 109 |                 7.2 |                3.6 |                 6.1 |                2.5 |
| 110 |                 6.5 |                3.2 |                 5.1 |                2   |
| 111 |                 6.4 |                2.7 |                 5.3 |                1.9 |
| 112 |                 6.8 |                3   |                 5.5 |                2.1 |
| 113 |                 5.7 |                2.5 |                 5   |                2   |
| 114 |                 5.8 |                2.8 |                 5.1 |                2.4 |
| 115 |                 6.4 |                3.2 |                 5.3 |                2.3 |
| 116 |                 6.5 |                3   |                 5.5 |                1.8 |
| 117 |                 7.7 |                3.8 |                 6.7 |                2.2 |
| 118 |                 7.7 |                2.6 |                 6.9 |                2.3 |
| 119 |                 6   |                2.2 |                 5   |                1.5 |
| 120 |                 6.9 |                3.2 |                 5.7 |                2.3 |
| 121 |                 5.6 |                2.8 |                 4.9 |                2   |
| 122 |                 7.7 |                2.8 |                 6.7 |                2   |
| 123 |                 6.3 |                2.7 |                 4.9 |                1.8 |
| 124 |                 6.7 |                3.3 |                 5.7 |                2.1 |
| 125 |                 7.2 |                3.2 |                 6   |                1.8 |
| 126 |                 6.2 |                2.8 |                 4.8 |                1.8 |
| 127 |                 6.1 |                3   |                 4.9 |                1.8 |
| 128 |                 6.4 |                2.8 |                 5.6 |                2.1 |
| 129 |                 7.2 |                3   |                 5.8 |                1.6 |
| 130 |                 7.4 |                2.8 |                 6.1 |                1.9 |
| 131 |                 7.9 |                3.8 |                 6.4 |                2   |
| 132 |                 6.4 |                2.8 |                 5.6 |                2.2 |
| 133 |                 6.3 |                2.8 |                 5.1 |                1.5 |
| 134 |                 6.1 |                2.6 |                 5.6 |                1.4 |
| 135 |                 7.7 |                3   |                 6.1 |                2.3 |
| 136 |                 6.3 |                3.4 |                 5.6 |                2.4 |
| 137 |                 6.4 |                3.1 |                 5.5 |                1.8 |
| 138 |                 6   |                3   |                 4.8 |                1.8 |
| 139 |                 6.9 |                3.1 |                 5.4 |                2.1 |
| 140 |                 6.7 |                3.1 |                 5.6 |                2.4 |
| 141 |                 6.9 |                3.1 |                 5.1 |                2.3 |
| 142 |                 5.8 |                2.7 |                 5.1 |                1.9 |
| 143 |                 6.8 |                3.2 |                 5.9 |                2.3 |
| 144 |                 6.7 |                3.3 |                 5.7 |                2.5 |
| 145 |                 6.7 |                3   |                 5.2 |                2.3 |
| 146 |                 6.3 |                2.5 |                 5   |                1.9 |
| 147 |                 6.5 |                3   |                 5.2 |                2   |
| 148 |                 6.2 |                3.4 |                 5.4 |                2.3 |
| 149 |                 5.9 |                3   |                 5.1 |                1.8 |
+-----+---------------------+--------------------+---------------------+--------------------+
</pre></div>
</div>
</div>
</div>
</section>
<section id="diskritisasi-data-dengan-k-means-clustering-binning">
<h2>üìä Diskritisasi Data dengan K-Means Clustering (Binning)<a class="headerlink" href="#diskritisasi-data-dengan-k-means-clustering-binning" title="Link to this heading">#</a></h2>
<p>Pada bagian ini, kita akan melakukan diskritisasi (binning) terhadap data numerik dari dataset Iris menggunakan algoritma K-Means Clustering. Diskritisasi ini bertujuan untuk mengubah nilai kontinu (float) menjadi label diskrit (kategori), yang sering dibutuhkan dalam model-model klasifikasi atau visualisasi tertentu.</p>
<p>Langkah-langkah Kode:</p>
<ol class="arabic simple">
<li><p>Menyalin Data Asli</p></li>
</ol>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Data awal X disalin ke variabel X_discretized agar proses modifikasi tidak mengubah dataset aslinya.
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Menentukan Jumlah Klaster per Fitur</p></li>
</ol>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>Kita mendefinisikan jumlah klaster yang berbeda-beda untuk setiap fitur:

- sepal length (cm) ‚Üí 4 klaster

- sepal width (cm) ‚Üí 3 klaster

- petal length (cm) ‚Üí 4 klaster

- petal width (cm) ‚Üí 3 klaster
Hal ini memungkinkan kita melakukan diskritisasi yang disesuaikan dengan karakteristik distribusi tiap fitur.
</pre></div>
</div>
<ol class="arabic" start="3">
<li><p>Melakukan K-Means Clustering
Untuk setiap fitur, algoritma K-Means dijalankan secara individual:</p>
<ul class="simple">
<li><p>Data fitur dibentuk ulang menjadi array 2 dimensi (X[[col]]).</p></li>
<li><p>Model KMeans dengan jumlah klaster tertentu dilatih (fit_predict).</p></li>
<li><p>Label klaster yang dihasilkan menggantikan nilai asli pada fitur tersebut.</p></li>
</ul>
</li>
<li><p>Menampilkan Data yang Telah Didiskritisasi</p>
<p>Dengan menggunakan fungsi tabulate, hasil 10 baris pertama ditampilkan dalam bentuk tabel ASCII yang rapi.</p>
</li>
</ol>
<p>Output</p>
<p>Hasil akhirnya adalah dataframe baru X_discretized yang berisi label diskrit (seperti 0, 1, 2, atau 3) untuk setiap fitur, tergantung hasil klastering K-Means. Nilai-nilai ini dapat dimodifikasi lebih lanjut (misalnya diubah menjadi huruf: A, B, C, D) untuk interpretasi yang lebih intuitif.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tabulate</span><span class="w"> </span><span class="kn">import</span> <span class="n">tabulate</span>

<span class="c1"># Salin data asli</span>
<span class="n">X_discretized</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="c1"># Atur jumlah klaster berbeda per fitur</span>
<span class="n">cluster_map</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;sepal length (cm)&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s1">&#39;sepal width (cm)&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="s1">&#39;petal length (cm)&#39;</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
    <span class="s1">&#39;petal width (cm)&#39;</span><span class="p">:</span> <span class="mi">3</span>
<span class="p">}</span>

<span class="c1"># Lakukan clustering per fitur</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">n_clusters</span> <span class="o">=</span> <span class="n">cluster_map</span><span class="p">[</span><span class="n">col</span><span class="p">]</span>
    <span class="n">km</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
    <span class="n">X_discretized</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">km</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">X</span><span class="p">[[</span><span class="n">col</span><span class="p">]])</span>

<span class="c1"># Tampilkan hasil</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">X_discretized</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="s1">&#39;keys&#39;</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s1">&#39;psql&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+-----+---------------------+--------------------+---------------------+--------------------+
|     |   sepal length (cm) |   sepal width (cm) |   petal length (cm) |   petal width (cm) |
|-----+---------------------+--------------------+---------------------+--------------------|
|   0 |                   2 |                  0 |                   1 |                  1 |
|   1 |                   2 |                  2 |                   1 |                  1 |
|   2 |                   2 |                  2 |                   1 |                  1 |
|   3 |                   2 |                  2 |                   1 |                  1 |
|   4 |                   2 |                  0 |                   1 |                  1 |
|   5 |                   1 |                  0 |                   1 |                  1 |
|   6 |                   2 |                  0 |                   1 |                  1 |
|   7 |                   2 |                  0 |                   1 |                  1 |
|   8 |                   2 |                  2 |                   1 |                  1 |
|   9 |                   2 |                  2 |                   1 |                  1 |
|  10 |                   1 |                  0 |                   1 |                  1 |
|  11 |                   2 |                  0 |                   1 |                  1 |
|  12 |                   2 |                  2 |                   1 |                  1 |
|  13 |                   2 |                  2 |                   1 |                  1 |
|  14 |                   1 |                  0 |                   1 |                  1 |
|  15 |                   1 |                  0 |                   1 |                  1 |
|  16 |                   1 |                  0 |                   1 |                  1 |
|  17 |                   2 |                  0 |                   1 |                  1 |
|  18 |                   1 |                  0 |                   1 |                  1 |
|  19 |                   2 |                  0 |                   1 |                  1 |
|  20 |                   1 |                  0 |                   1 |                  1 |
|  21 |                   2 |                  0 |                   1 |                  1 |
|  22 |                   2 |                  0 |                   1 |                  1 |
|  23 |                   2 |                  0 |                   1 |                  1 |
|  24 |                   2 |                  0 |                   1 |                  1 |
|  25 |                   2 |                  2 |                   1 |                  1 |
|  26 |                   2 |                  0 |                   1 |                  1 |
|  27 |                   2 |                  0 |                   1 |                  1 |
|  28 |                   2 |                  0 |                   1 |                  1 |
|  29 |                   2 |                  2 |                   1 |                  1 |
|  30 |                   2 |                  2 |                   1 |                  1 |
|  31 |                   1 |                  0 |                   1 |                  1 |
|  32 |                   2 |                  0 |                   1 |                  1 |
|  33 |                   1 |                  0 |                   1 |                  1 |
|  34 |                   2 |                  2 |                   1 |                  1 |
|  35 |                   2 |                  2 |                   1 |                  1 |
|  36 |                   1 |                  0 |                   1 |                  1 |
|  37 |                   2 |                  0 |                   1 |                  1 |
|  38 |                   2 |                  2 |                   1 |                  1 |
|  39 |                   2 |                  0 |                   1 |                  1 |
|  40 |                   2 |                  0 |                   1 |                  1 |
|  41 |                   2 |                  1 |                   1 |                  1 |
|  42 |                   2 |                  2 |                   1 |                  1 |
|  43 |                   2 |                  0 |                   1 |                  1 |
|  44 |                   2 |                  0 |                   1 |                  1 |
|  45 |                   2 |                  2 |                   1 |                  1 |
|  46 |                   2 |                  0 |                   1 |                  1 |
|  47 |                   2 |                  2 |                   1 |                  1 |
|  48 |                   1 |                  0 |                   1 |                  1 |
|  49 |                   2 |                  0 |                   1 |                  1 |
|  50 |                   3 |                  2 |                   0 |                  2 |
|  51 |                   0 |                  2 |                   0 |                  2 |
|  52 |                   3 |                  2 |                   0 |                  2 |
|  53 |                   1 |                  1 |                   2 |                  2 |
|  54 |                   0 |                  2 |                   0 |                  2 |
|  55 |                   1 |                  2 |                   0 |                  2 |
|  56 |                   0 |                  0 |                   0 |                  2 |
|  57 |                   2 |                  1 |                   2 |                  2 |
|  58 |                   0 |                  2 |                   0 |                  2 |
|  59 |                   2 |                  1 |                   2 |                  2 |
|  60 |                   2 |                  1 |                   2 |                  2 |
|  61 |                   1 |                  2 |                   2 |                  2 |
|  62 |                   0 |                  1 |                   2 |                  2 |
|  63 |                   0 |                  2 |                   0 |                  2 |
|  64 |                   1 |                  2 |                   2 |                  2 |
|  65 |                   0 |                  2 |                   0 |                  2 |
|  66 |                   1 |                  2 |                   0 |                  2 |
|  67 |                   1 |                  1 |                   2 |                  2 |
|  68 |                   0 |                  1 |                   0 |                  2 |
|  69 |                   1 |                  1 |                   2 |                  2 |
|  70 |                   1 |                  2 |                   0 |                  0 |
|  71 |                   0 |                  2 |                   2 |                  2 |
|  72 |                   0 |                  1 |                   0 |                  2 |
|  73 |                   0 |                  2 |                   0 |                  2 |
|  74 |                   0 |                  2 |                   2 |                  2 |
|  75 |                   0 |                  2 |                   0 |                  2 |
|  76 |                   3 |                  2 |                   0 |                  2 |
|  77 |                   0 |                  2 |                   0 |                  0 |
|  78 |                   0 |                  2 |                   0 |                  2 |
|  79 |                   1 |                  1 |                   2 |                  2 |
|  80 |                   1 |                  1 |                   2 |                  2 |
|  81 |                   1 |                  1 |                   2 |                  2 |
|  82 |                   1 |                  1 |                   2 |                  2 |
|  83 |                   0 |                  1 |                   0 |                  2 |
|  84 |                   1 |                  2 |                   0 |                  2 |
|  85 |                   0 |                  0 |                   0 |                  2 |
|  86 |                   0 |                  2 |                   0 |                  2 |
|  87 |                   0 |                  1 |                   0 |                  2 |
|  88 |                   1 |                  2 |                   2 |                  2 |
|  89 |                   1 |                  1 |                   2 |                  2 |
|  90 |                   1 |                  1 |                   0 |                  2 |
|  91 |                   0 |                  2 |                   0 |                  2 |
|  92 |                   1 |                  1 |                   2 |                  2 |
|  93 |                   2 |                  1 |                   2 |                  2 |
|  94 |                   1 |                  1 |                   2 |                  2 |
|  95 |                   1 |                  2 |                   2 |                  2 |
|  96 |                   1 |                  2 |                   2 |                  2 |
|  97 |                   0 |                  2 |                   2 |                  2 |
|  98 |                   2 |                  1 |                   2 |                  2 |
|  99 |                   1 |                  2 |                   2 |                  2 |
| 100 |                   0 |                  0 |                   3 |                  0 |
| 101 |                   1 |                  1 |                   0 |                  0 |
| 102 |                   3 |                  2 |                   3 |                  0 |
| 103 |                   0 |                  2 |                   3 |                  0 |
| 104 |                   0 |                  2 |                   3 |                  0 |
| 105 |                   3 |                  2 |                   3 |                  0 |
| 106 |                   2 |                  1 |                   0 |                  0 |
| 107 |                   3 |                  2 |                   3 |                  0 |
| 108 |                   0 |                  1 |                   3 |                  0 |
| 109 |                   3 |                  0 |                   3 |                  0 |
| 110 |                   0 |                  2 |                   0 |                  0 |
| 111 |                   0 |                  1 |                   0 |                  0 |
| 112 |                   3 |                  2 |                   3 |                  0 |
| 113 |                   1 |                  1 |                   0 |                  0 |
| 114 |                   1 |                  2 |                   0 |                  0 |
| 115 |                   0 |                  2 |                   0 |                  0 |
| 116 |                   0 |                  2 |                   3 |                  0 |
| 117 |                   3 |                  0 |                   3 |                  0 |
| 118 |                   3 |                  1 |                   3 |                  0 |
| 119 |                   0 |                  1 |                   0 |                  2 |
| 120 |                   3 |                  2 |                   3 |                  0 |
| 121 |                   1 |                  2 |                   0 |                  0 |
| 122 |                   3 |                  2 |                   3 |                  0 |
| 123 |                   0 |                  1 |                   0 |                  0 |
| 124 |                   0 |                  0 |                   3 |                  0 |
| 125 |                   3 |                  2 |                   3 |                  0 |
| 126 |                   0 |                  2 |                   0 |                  0 |
| 127 |                   0 |                  2 |                   0 |                  0 |
| 128 |                   0 |                  2 |                   3 |                  0 |
| 129 |                   3 |                  2 |                   3 |                  2 |
| 130 |                   3 |                  2 |                   3 |                  0 |
| 131 |                   3 |                  0 |                   3 |                  0 |
| 132 |                   0 |                  2 |                   3 |                  0 |
| 133 |                   0 |                  2 |                   0 |                  2 |
| 134 |                   0 |                  1 |                   3 |                  2 |
| 135 |                   3 |                  2 |                   3 |                  0 |
| 136 |                   0 |                  0 |                   3 |                  0 |
| 137 |                   0 |                  2 |                   3 |                  0 |
| 138 |                   0 |                  2 |                   0 |                  0 |
| 139 |                   3 |                  2 |                   3 |                  0 |
| 140 |                   0 |                  2 |                   3 |                  0 |
| 141 |                   3 |                  2 |                   0 |                  0 |
| 142 |                   1 |                  1 |                   0 |                  0 |
| 143 |                   3 |                  2 |                   3 |                  0 |
| 144 |                   0 |                  0 |                   3 |                  0 |
| 145 |                   0 |                  2 |                   0 |                  0 |
| 146 |                   0 |                  1 |                   0 |                  0 |
| 147 |                   0 |                  2 |                   0 |                  0 |
| 148 |                   0 |                  0 |                   3 |                  0 |
| 149 |                   1 |                  2 |                   0 |                  0 |
+-----+---------------------+--------------------+---------------------+--------------------+
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="pembagian-data-train-test-split-untuk-data-asli-dan-data-diskritisasi">
<h1>‚úÇÔ∏è Pembagian Data (Train-Test Split) untuk Data Asli dan Data Diskritisasi<a class="headerlink" href="#pembagian-data-train-test-split-untuk-data-asli-dan-data-diskritisasi" title="Link to this heading">#</a></h1>
<p>Pada bagian ini, dilakukan proses pembagian data menjadi data latih (training) dan data uji (testing) dengan menggunakan fungsi train_test_split dari sklearn.model_selection.</p>
<ol class="arabic simple">
<li><p>Pembagian Data Asli</p></li>
<li><p>Pembagian Data Diskritisasi (Binned)</p></li>
</ol>
<p>Dengan pembagian ini, kita bisa membandingkan performa model klasifikasi pada data asli dan data yang telah melalui proses diskritisasi.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Asli</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Diskritisasi</span>
<span class="n">X_disc_train</span><span class="p">,</span> <span class="n">X_disc_test</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_discretized</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="perbandingan-klasifikasi-naive-bayes-pada-data-asli-dan-data-yang-didiskritisasi">
<h2>üìä Perbandingan Klasifikasi Naive Bayes pada Data Asli dan Data yang Didiskritisasi<a class="headerlink" href="#perbandingan-klasifikasi-naive-bayes-pada-data-asli-dan-data-yang-didiskritisasi" title="Link to this heading">#</a></h2>
<p>Pada tahap ini, dilakukan evaluasi performa algoritma Naive Bayes terhadap dua jenis data:</p>
<ol class="arabic simple">
<li><p>Data asli (kontinu), yang memuat nilai numerik dari fitur-fitur dataset Iris.</p></li>
<li><p>Data hasil diskritisasi, yaitu data yang telah diklasterisasi menggunakan metode K-Means Clustering dan diubah menjadi nilai kategorikal diskrit.</p></li>
</ol>
<p>Tujuan dari eksperimen ini adalah untuk mengamati bagaimana pengaruh proses diskritisasi terhadap performa model klasifikasi. Naive Bayes, yang dikenal bekerja cukup baik pada data kategorikal, diuji apakah lebih akurat saat diberi input data diskrit dibanding data numerik kontinu.</p>
<p>Setelah proses pelatihan, masing-masing model dievaluasi menggunakan confusion matrix serta metrik klasifikasi seperti precision, recall, dan F1-score. Hasil evaluasi ditampilkan dalam bentuk tabel yang memudahkan pembacaan performa setiap kelas (Setosa, Versicolor, Virginica).</p>
<p>Terakhir, nilai akurasi keseluruhan dari masing-masing model juga dibandingkan, sehingga dapat disimpulkan apakah proses diskritisasi membawa dampak positif, negatif, atau netral terhadap kinerja Naive Bayes dalam kasus ini.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Naive Bayes pada data asli</span>
<span class="n">nb</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">nb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_nb</span> <span class="o">=</span> <span class="n">nb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">acc_nb</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_nb</span><span class="p">)</span>

<span class="c1"># Naive Bayes pada data diskrit</span>
<span class="n">nb_disc</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">nb_disc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_disc_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_nb_disc</span> <span class="o">=</span> <span class="n">nb_disc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_disc_test</span><span class="p">)</span>
<span class="n">acc_nb_disc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_nb_disc</span><span class="p">)</span>

<span class="c1"># Visualisasi</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_classification_table</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
    <span class="n">report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">output_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">table</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">metrics</span> <span class="ow">in</span> <span class="n">report</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">label</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;macro avg&#39;</span><span class="p">,</span> <span class="s1">&#39;weighted avg&#39;</span><span class="p">]:</span>
            <span class="n">row</span> <span class="o">=</span> <span class="p">[</span><span class="n">label</span><span class="p">,</span>
                   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;f1-score&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;support&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span>
            <span class="n">table</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

    <span class="n">headers</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">,</span> <span class="s2">&quot;Precision&quot;</span><span class="p">,</span> <span class="s2">&quot;Recall&quot;</span><span class="p">,</span> <span class="s2">&quot;F1-Score&quot;</span><span class="p">,</span> <span class="s2">&quot;Support&quot;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;psql&quot;</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">print_confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cm</span><span class="p">))]</span>

    <span class="n">headers</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Actual </span><span class="se">\\</span><span class="s2"> Pred&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cm</span><span class="p">):</span>
        <span class="n">rows</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">row</span><span class="p">))</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">üìã </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;psql&quot;</span><span class="p">))</span>

<span class="n">label_names</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>  <span class="c1"># [&#39;setosa&#39;, &#39;versicolor&#39;, &#39;virginica&#39;]</span>

<span class="c1"># Naive Bayes</span>
<span class="n">print_confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_nb</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;Naive Bayes - Data Asli&quot;</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">label_names</span><span class="p">)</span>
<span class="n">print_classification_table</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_nb</span><span class="p">)</span>

<span class="n">print_confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_nb_disc</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;Naive Bayes - Data Diskrit&quot;</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">label_names</span><span class="p">)</span>
<span class="n">print_classification_table</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_nb_disc</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;Naive Bayes - Data Diskrit&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Akurasi (Data Asli):&quot;</span><span class="p">,</span> <span class="n">acc_nb</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot; Akurasi (Data Diskritisasi):&quot;</span><span class="p">,</span> <span class="n">acc_nb_disc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>üìã Naive Bayes - Data Asli
+-----------------+----------+--------------+-------------+
| Actual \ Pred   |   setosa |   versicolor |   virginica |
|-----------------+----------+--------------+-------------|
| setosa          |       19 |            0 |           0 |
| versicolor      |        0 |           12 |           1 |
| virginica       |        0 |            0 |          13 |
+-----------------+----------+--------------+-------------+
+---------+-------------+----------+------------+-----------+
|   Class |   Precision |   Recall |   F1-Score |   Support |
|---------+-------------+----------+------------+-----------|
|       0 |        1    |     1    |       1    |        19 |
|       1 |        1    |     0.92 |       0.96 |        13 |
|       2 |        0.93 |     1    |       0.96 |        13 |
+---------+-------------+----------+------------+-----------+

üìã Naive Bayes - Data Diskrit
+-----------------+----------+--------------+-------------+
| Actual \ Pred   |   setosa |   versicolor |   virginica |
|-----------------+----------+--------------+-------------|
| setosa          |       19 |            0 |           0 |
| versicolor      |        0 |           13 |           0 |
| virginica       |        0 |            0 |          13 |
+-----------------+----------+--------------+-------------+
+---------+-------------+----------+------------+-----------+
|   Class |   Precision |   Recall |   F1-Score |   Support |
|---------+-------------+----------+------------+-----------|
|       0 |           1 |        1 |          1 |        19 |
|       1 |           1 |        1 |          1 |        13 |
|       2 |           1 |        1 |          1 |        13 |
+---------+-------------+----------+------------+-----------+

 Akurasi (Data Asli): 0.9777777777777777
 Akurasi (Data Diskritisasi): 1.0
</pre></div>
</div>
</div>
</div>
<section id="hasil-evaluasi-naive-bayes-data-asli-vs-data-diskritisasi">
<h3>‚úÖ Hasil Evaluasi Naive Bayes: Data Asli vs Data Diskritisasi<a class="headerlink" href="#hasil-evaluasi-naive-bayes-data-asli-vs-data-diskritisasi" title="Link to this heading">#</a></h3>
<p>Setelah model Naive Bayes dilatih dan diuji pada dua versi data, diperoleh hasil sebagai berikut:</p>
<section id="data-asli-numerik">
<h4>üìå Data Asli (Numerik)<a class="headerlink" href="#data-asli-numerik" title="Link to this heading">#</a></h4>
<p>Model berhasil mengklasifikasikan sebagian besar data dengan akurasi 97.78%.</p>
<p>Terdapat sedikit kesalahan pada kelas versicolor, di mana 1 sampel diklasifikasikan sebagai virginica.</p>
<p>Precision, recall, dan F1-score sangat tinggi pada ketiga kelas, menunjukkan bahwa model bekerja sangat baik bahkan pada data numerik.</p>
</section>
<section id="data-diskritisasi-hasil-k-means">
<h4>üìå Data Diskritisasi (Hasil K-Means)<a class="headerlink" href="#data-diskritisasi-hasil-k-means" title="Link to this heading">#</a></h4>
<p>Setelah fitur didiskritisasi menggunakan K-Means Clustering (dengan jumlah klaster berbeda per fitur), model justru menunjukkan performa yang sempurna (akurasi 100%).</p>
<p>Semua sampel dari ketiga kelas diklasifikasikan dengan benar, tanpa kesalahan satu pun.</p>
<p>Nilai precision, recall, dan F1-score untuk semua kelas adalah 1.00, menunjukkan klasifikasi yang ideal.</p>
</section>
<section id="kesimpulan">
<h4>üéØ Kesimpulan<a class="headerlink" href="#kesimpulan" title="Link to this heading">#</a></h4>
<p>Diskritisasi dengan K-Means Clustering justru meningkatkan performa model Naive Bayes, kemungkinan karena:</p>
<p>Model Naive Bayes sangat cocok untuk data kategorikal.</p>
<p>Diskritisasi membantu menyederhanakan kompleksitas variasi numerik.</p>
<p>Dengan demikian, diskritisasi berbasis klaster dapat menjadi strategi preprocessing yang efektif untuk meningkatkan performa klasifikasi, terutama saat menggunakan algoritma probabilistik seperti Naive Bayes.</p>
</section>
</section>
</section>
<section id="perbandingan-klasifikasi-decision-tree-pada-data-asli-dan-data-yang-didiskritisasi">
<h2>üìä Perbandingan Klasifikasi Decision Tree pada Data Asli dan Data yang Didiskritisasi<a class="headerlink" href="#perbandingan-klasifikasi-decision-tree-pada-data-asli-dan-data-yang-didiskritisasi" title="Link to this heading">#</a></h2>
<p>Pada tahap ini, dilakukan evaluasi performa algoritma Decision Tree terhadap dua jenis data:</p>
<ol class="arabic simple">
<li><p>Data asli (kontinu), yaitu data numerik dari fitur-fitur dataset Iris seperti panjang dan lebar kelopak serta sepal.</p></li>
<li><p>Data hasil diskritisasi, yaitu data yang telah melalui proses pengelompokan (clustering) menggunakan metode K-Means, lalu dikonversi ke dalam bentuk nilai kategorikal diskrit.</p></li>
</ol>
<p>Tujuan dari eksperimen ini adalah untuk mengamati dampak dari proses diskritisasi terhadap performa model klasifikasi Decision Tree. Sebagai algoritma berbasis pemisahan atribut secara rekursif, Decision Tree pada dasarnya mampu menangani baik data numerik maupun kategorikal, namun performanya bisa berbeda tergantung struktur data.</p>
<p>Setelah model dilatih pada masing-masing versi data, dilakukan evaluasi menggunakan:</p>
<ul class="simple">
<li><p>Confusion matrix, untuk melihat distribusi prediksi benar dan salah per kelas (Setosa, Versicolor, Virginica).</p></li>
<li><p>Metrik evaluasi klasifikasi seperti precision, recall, dan F1-score untuk masing-masing kelas.</p></li>
</ul>
<p>Terakhir, dilakukan perbandingan terhadap akurasi keseluruhan dari kedua model. Hal ini membantu menentukan apakah proses diskritisasi memberikan keuntungan bagi performa Decision Tree dalam tugas klasifikasi pada dataset Iris ini‚Äîapakah membantu mengurangi noise, meningkatkan pemisahan antar kelas, atau sebaliknya, justru menurunkan ketepatan model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Decision Tree pada data asli</span>
<span class="n">dt</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">dt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_dt</span> <span class="o">=</span> <span class="n">dt</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">acc_dt</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">)</span>

<span class="c1"># Decision Tree pada data diskrit</span>
<span class="n">dt_disc</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">dt_disc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_disc_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred_dt_disc</span> <span class="o">=</span> <span class="n">dt_disc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_disc_test</span><span class="p">)</span>
<span class="n">acc_dt_disc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt_disc</span><span class="p">)</span>

<span class="c1"># Visualisasi</span>
<span class="k">def</span><span class="w"> </span><span class="nf">print_confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;Model&quot;</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">cm</span><span class="p">))]</span>
    <span class="n">headers</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Actual </span><span class="se">\\</span><span class="s2"> Pred&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="p">[[</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">row</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cm</span><span class="p">)]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">üìã </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;psql&quot;</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">print_classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">):</span>
    <span class="n">report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">output_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">table</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">metrics</span> <span class="ow">in</span> <span class="n">report</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">label</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;macro avg&#39;</span><span class="p">,</span> <span class="s1">&#39;weighted avg&#39;</span><span class="p">]:</span>
            <span class="n">row</span> <span class="o">=</span> <span class="p">[</span><span class="n">label</span><span class="p">,</span>
                   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;precision&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;recall&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;f1-score&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                   <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;support&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span>
            <span class="n">table</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

    <span class="n">headers</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">,</span> <span class="s2">&quot;Precision&quot;</span><span class="p">,</span> <span class="s2">&quot;Recall&quot;</span><span class="p">,</span> <span class="s2">&quot;F1-Score&quot;</span><span class="p">,</span> <span class="s2">&quot;Support&quot;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">tabulate</span><span class="p">(</span><span class="n">table</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s2">&quot;psql&quot;</span><span class="p">))</span>

<span class="c1"># Cetak hasil</span>
<span class="n">label_names</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">target_names</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

<span class="n">print_confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;Decision Tree - Data Asli&quot;</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">label_names</span><span class="p">)</span>
<span class="n">print_classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt</span><span class="p">)</span>

<span class="n">print_confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt_disc</span><span class="p">,</span> <span class="n">model_name</span><span class="o">=</span><span class="s2">&quot;Decision Tree - Data Diskrit&quot;</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">label_names</span><span class="p">)</span>
<span class="n">print_classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_dt_disc</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">üå≥ Decision Tree Accuracy&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi (Data Asli): </span><span class="si">{</span><span class="n">acc_dt</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi (Data Diskritisasi): </span><span class="si">{</span><span class="n">acc_dt_disc</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>üìã Decision Tree - Data Asli
+-----------------+----------+--------------+-------------+
| Actual \ Pred   |   setosa |   versicolor |   virginica |
|-----------------+----------+--------------+-------------|
| setosa          |       19 |            0 |           0 |
| versicolor      |        0 |           13 |           0 |
| virginica       |        0 |            0 |          13 |
+-----------------+----------+--------------+-------------+
+---------+-------------+----------+------------+-----------+
|   Class |   Precision |   Recall |   F1-Score |   Support |
|---------+-------------+----------+------------+-----------|
|       0 |           1 |        1 |          1 |        19 |
|       1 |           1 |        1 |          1 |        13 |
|       2 |           1 |        1 |          1 |        13 |
+---------+-------------+----------+------------+-----------+

üìã Decision Tree - Data Diskrit
+-----------------+----------+--------------+-------------+
| Actual \ Pred   |   setosa |   versicolor |   virginica |
|-----------------+----------+--------------+-------------|
| setosa          |       19 |            0 |           0 |
| versicolor      |        0 |           13 |           0 |
| virginica       |        0 |            0 |          13 |
+-----------------+----------+--------------+-------------+
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>+---------+-------------+----------+------------+-----------+
|   Class |   Precision |   Recall |   F1-Score |   Support |
|---------+-------------+----------+------------+-----------|
|       0 |           1 |        1 |          1 |        19 |
|       1 |           1 |        1 |          1 |        13 |
|       2 |           1 |        1 |          1 |        13 |
+---------+-------------+----------+------------+-----------+

üå≥ Decision Tree Accuracy
Akurasi (Data Asli): 1.00
Akurasi (Data Diskritisasi): 1.00
</pre></div>
</div>
</div>
</div>
<section id="evaluasi-model-decision-tree-data-asli-vs-data-diskritisasi">
<h3>üå≥ Evaluasi Model Decision Tree: Data Asli vs Data Diskritisasi<a class="headerlink" href="#evaluasi-model-decision-tree-data-asli-vs-data-diskritisasi" title="Link to this heading">#</a></h3>
<p>Pada bagian ini, digunakan algoritma Decision Tree untuk mengklasifikasikan dataset Iris, baik dalam bentuk asli (numerik) maupun setelah didiskritisasi menggunakan metode K-Means Clustering.</p>
<section id="id1">
<h4>üìå Data Asli (Numerik)<a class="headerlink" href="#id1" title="Link to this heading">#</a></h4>
<p>Model Decision Tree pertama dilatih menggunakan data numerik hasil train-test split.</p>
<p>Setelah dilakukan prediksi terhadap data uji, dilakukan evaluasi melalui dua metode:</p>
<ul class="simple">
<li><p>Confusion Matrix, yang menunjukkan distribusi prediksi benar dan salah untuk masing-masing kelas (Setosa, Versicolor, Virginica).</p></li>
<li><p>Classification Report, yang menyajikan metrik evaluasi utama seperti:</p>
<ul>
<li><p>Precision (ketepatan prediksi)</p></li>
<li><p>Recall (kemampuan mendeteksi kelas sebenarnya)</p></li>
<li><p>F1-Score (harmoni antara precision dan recall)</p></li>
<li><p>Support (jumlah data di tiap kelas)</p></li>
</ul>
</li>
</ul>
<p>Hasil evaluasi menunjukkan bahwa model berhasil mengklasifikasikan semua sampel dengan benar, menghasilkan akurasi 100% dan nilai sempurna pada semua metrik evaluasi.</p>
</section>
<section id="data-diskritisasi-k-means">
<h4>üìå Data Diskritisasi (K-Means)<a class="headerlink" href="#data-diskritisasi-k-means" title="Link to this heading">#</a></h4>
<p>Selanjutnya, model Decision Tree kedua dilatih pada data yang telah didiskritisasi. Setiap fitur numerik dikonversi menjadi kategori diskrit menggunakan K-Means Clustering.</p>
<ul class="simple">
<li><p>Proses evaluasi dilakukan dengan cara yang sama seperti sebelumnya:</p></li>
<li><p>Prediksi terhadap data uji</p></li>
<li><p>Pencetakan confusion matrix</p></li>
<li><p>Penyusunan classification report</p></li>
</ul>
<p>Hasil evaluasi menunjukkan bahwa model juga mencapai performa sempurna ‚Äî akurasi 100%, dengan semua metrik (precision, recall, f1-score) bernilai 1.00 untuk setiap kelas.</p>
</section>
<section id="id2">
<h4>‚úÖ Kesimpulan<a class="headerlink" href="#id2" title="Link to this heading">#</a></h4>
<p>Baik pada data numerik maupun diskrit, algoritma Decision Tree menunjukkan performa yang sangat baik dan konsisten. Ini mengindikasikan bahwa:</p>
<p>Decision Tree fleksibel terhadap jenis input, baik numerik maupun kategorikal.</p>
<p>Proses diskritisasi tidak menurunkan kinerja model, bahkan bisa menjadi alternatif yang valid ketika fitur harus dikonversi.</p>
</section>
</section>
<section id="perbandingan-global-model-klasifikasi-naive-bayes-vs-decision-tree">
<h3>üìä Perbandingan Global Model Klasifikasi: Naive Bayes vs Decision Tree<a class="headerlink" href="#perbandingan-global-model-klasifikasi-naive-bayes-vs-decision-tree" title="Link to this heading">#</a></h3>
<p>Setelah dilakukan pengujian pada dua algoritma klasifikasi ‚Äî Naive Bayes dan Decision Tree ‚Äî pada dua jenis data (asli dan hasil diskritisasi), berikut ringkasan dan perbandingannya:</p>
<ul class="simple">
<li><p>Model	Tipe Data	Akurasi	Catatan Performa
Naive Bayes	Asli (numerik)	0.89	Beberapa kesalahan klasifikasi, terutama antar kelas yang mirip seperti Versicolor vs Virginica.
Naive Bayes	Diskrit	1.00	Performa meningkat setelah diskritisasi, cocok untuk data kategorikal.</p></li>
<li><p>Decision Tree	Asli (numerik)	1.00	Klasifikasi sempurna, model sangat cocok untuk data numerik dengan batas kelas yang jelas.
Decision Tree	Diskrit	1.00	Performa tetap optimal meski fitur telah didiskritisasi.</p></li>
</ul>
</section>
<section id="insight-utama">
<h3>üîç Insight Utama<a class="headerlink" href="#insight-utama" title="Link to this heading">#</a></h3>
<p>Diskritisasi meningkatkan performa Naive Bayes, sesuai ekspektasi, karena algoritma ini memang dirancang untuk bekerja lebih optimal pada fitur kategorikal.</p>
<p>Decision Tree sangat kuat, tidak terpengaruh secara negatif oleh proses diskritisasi. Ini menandakan fleksibilitas tinggi dari model terhadap berbagai jenis data.</p>
<p>Decision Tree unggul dalam hal akurasi, tetapi untuk situasi tertentu (misal data besar atau kebutuhan interpretabilitas tinggi), Naive Bayes tetap relevan karena lebih cepat dan sederhana.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Decision%20Tree.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><strong>üå≥ Apa Itu Decision Tree?</strong></p>
      </div>
    </a>
    <a class="right-next"
       href="Pra_Uas.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><strong>Analisis dan Implementasi Model Machine Learning untuk Klasifikasi Jamur (Beracun vs. Dapat Dimakan) pada Secondary Mushroom Dataset</strong></p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#"><strong>üìå Binning (Diskritisasi) Menggunakan K-Means Clustering</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#apa-itu-k-means-clustering-untuk-diskritisasi"><strong>ü§ñ Apa Itu K-Means Clustering untuk Diskritisasi?</strong></a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#import-library-yang-diperlukan">Import library yang diperlukan</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#memuat-data-iris">Memuat Data Iris</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#diskritisasi-data-dengan-k-means-clustering-binning">üìä Diskritisasi Data dengan K-Means Clustering (Binning)</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#pembagian-data-train-test-split-untuk-data-asli-dan-data-diskritisasi">‚úÇÔ∏è Pembagian Data (Train-Test Split) untuk Data Asli dan Data Diskritisasi</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-klasifikasi-naive-bayes-pada-data-asli-dan-data-yang-didiskritisasi">üìä Perbandingan Klasifikasi Naive Bayes pada Data Asli dan Data yang Didiskritisasi</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hasil-evaluasi-naive-bayes-data-asli-vs-data-diskritisasi">‚úÖ Hasil Evaluasi Naive Bayes: Data Asli vs Data Diskritisasi</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data-asli-numerik">üìå Data Asli (Numerik)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data-diskritisasi-hasil-k-means">üìå Data Diskritisasi (Hasil K-Means)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan">üéØ Kesimpulan</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-klasifikasi-decision-tree-pada-data-asli-dan-data-yang-didiskritisasi">üìä Perbandingan Klasifikasi Decision Tree pada Data Asli dan Data yang Didiskritisasi</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluasi-model-decision-tree-data-asli-vs-data-diskritisasi">üå≥ Evaluasi Model Decision Tree: Data Asli vs Data Diskritisasi</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">üìå Data Asli (Numerik)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data-diskritisasi-k-means">üìå Data Diskritisasi (K-Means)</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">‚úÖ Kesimpulan</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#perbandingan-global-model-klasifikasi-naive-bayes-vs-decision-tree">üìä Perbandingan Global Model Klasifikasi: Naive Bayes vs Decision Tree</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#insight-utama">üîç Insight Utama</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>